{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import math \n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import rdkit as rd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import AtomPairs\n",
    "from rdkit import DataStructs\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem.AtomPairs.Pairs import GetAtomPairFingerprintAsBitVect\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(path: str, file_name: str):\n",
    "    dataframe = Data_gather(path, file_name, False, True)\n",
    "    dataframe = Data_Manipulation(dataframe)\n",
    "    dataframe = MoleculeGen(5, dataframe, True)\n",
    "    targets = ['Cp (J/mol*K)']\n",
    "    features = (list(set(list(dataframe.columns))-set(targets)))\n",
    "    x_data = dataframe[features].values\n",
    "    y_data = dataframe[targets].values\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "def Data_gather(path: str, file_name: str, CO: bool, drop_phase: bool) -> pd.DataFrame:\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    if CO == True:\n",
    "        df_CO = df[ df['Isomeric Smile'] != 'CO' ]\n",
    "        df = df.drop(df_CO.index, axis= 0)\n",
    "        \n",
    "    if drop_phase == True:\n",
    "        df_drop = df[df['Phase'] != 'liquid' ]\n",
    "        df = df.drop(df_drop.index, axis= 0)\n",
    "        df = df.drop(['Phase'], axis= 1)\n",
    "    else:\n",
    "        df['Phase'] = df['Phase'].map({'liquid': 1, 'vapor': 2})\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #Convert specific column to float64\n",
    "    #df = pd.to_numeric(df, errors='coerce')\n",
    "    #df\n",
    "\n",
    "    #search for any NaN values that may have slipped through the cracks\n",
    "    #row = df[df['Cp (J/mol*K)'].isnull()]\n",
    "    #print(row)\n",
    "    return df\n",
    "\n",
    "def MoleculeGen(rad: int, df: pd.DataFrame, Choice: bool) -> pd.DataFrame:\n",
    "    if Choice == True:\n",
    "        mol_list = []\n",
    "        fin_list = []\n",
    "        for smile in df['Isomeric Smile']:\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(smile)\n",
    "                mol_list.append(mol)\n",
    "                mf_bitvect = AllChem.GetMorganFingerprintAsBitVect(mol, radius=rad, nBits = 256)\n",
    "                temp_arr = np.zeros((0,), dtype=np.int8)\n",
    "                DataStructs.ConvertToNumpyArray(mf_bitvect, temp_arr)\n",
    "                fin_list.append(temp_arr)\n",
    "            except:\n",
    "                print(smile)\n",
    "        fin_list = pd.DataFrame(fin_list)\n",
    "        df = pd.concat([df, fin_list], axis= 1)\n",
    "    df = df.drop(['Isomeric Smile'], axis= 1)\n",
    "    return df\n",
    "\n",
    "def Data_Manipulation(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    Temperature = df['Temperature (K)'].values\n",
    "    Pressure = df['Pressure (bar)'].values\n",
    "    Tc = df['Tc'].values\n",
    "    Pc = df['Pc'].values\n",
    "    CP = df['Cp (J/mol*K)'].values\n",
    "    Isom = df['Isomeric Smile'].values\n",
    "    df = df.drop(['Isomeric Smile', 'Density (kg/m3)', 'Temperature (K)', 'Pressure (bar)', 'Cp (J/mol*K)', 'Tc', 'Pc'], axis= 1)\n",
    "    \n",
    "    Tr = Temperature/Tc\n",
    "    Pr = Pressure/Pc\n",
    "\n",
    "    temp = {'Isomeric Smile': Isom, 'Tr': Tr, 'Pr': Pr, 'Cp': CP}\n",
    "    temp = pd.DataFrame(temp)\n",
    "    df_drop = temp[temp['Tr'] >= 0.999]\n",
    "    temp = temp.drop(df_drop.index, axis= 0)\n",
    "    df_drop = temp[temp['Pr'] >= 0.999]\n",
    "    temp = temp.drop(df_drop.index, axis= 0)\n",
    "    temp = temp.reset_index(drop=True)\n",
    "\n",
    "    Isom = temp['Isomeric Smile'].values\n",
    "    Tr = temp['Tr'].values\n",
    "    Pr = temp['Pr'].values \n",
    "    CP = temp['Cp'].values\n",
    "\n",
    "    Temperature = np.power(np.arctanh(np.power(Tr, 29.12522)), 0.688902)\n",
    "    Pressure = np.power(np.arctanh(np.power(Pr, 0.99928)), 1.162695504)\n",
    "    CP = np.sqrt(np.log(np.power(np.log(CP), 1/3.061115817107)))\n",
    "\n",
    "\n",
    "    temp = {'Isomeric Smile': Isom, 'Temperature (K)': Temperature, 'Pressure (bar)': Pressure, 'Cp (J/mol*K)': CP}\n",
    "    temp = pd.DataFrame(temp)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "\n",
    "def sklearn_model_generation(split, h_layer, x_data, y_data, plot, save, file):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size= split, random_state=42, shuffle= True)\n",
    "    \n",
    "    ann_sklearn = MLPRegressor(hidden_layer_sizes= (h_layer), \n",
    "            activation= 'relu',\n",
    "            solver= 'adam',\n",
    "            alpha= 1e-4,\n",
    "            max_iter= 5000,\n",
    "            shuffle= True,\n",
    "            random_state= 42,\n",
    "            early_stopping= True\n",
    "            )\n",
    "    \n",
    "    ann_sklearn.fit(x_train, y_train.ravel())\n",
    "\n",
    "    score = ann_sklearn.score(x_test,y_test.ravel())\n",
    "    predict_test_set = ann_sklearn.predict(x_test)\n",
    "    RMSE = root_mean_squared_error(y_test, predict_test_set)\n",
    "    MSE = np.power(RMSE, 2)\n",
    "    print(f'R2 = {score}')\n",
    "    print(f'MSE = {MSE}')\n",
    "    print(f'RMSE = {RMSE}')\n",
    "\n",
    "    if plot == True:\n",
    "        plot_results(ann_sklearn, x_test, y_test, save, file)\n",
    "    return ann_sklearn\n",
    "\n",
    "def save_model(x_data, y_data, h_layer, ann_sklearn, ANN, Filepath):\n",
    "    weights = ann_sklearn.coeffs_\n",
    "    bias = ann_sklearn.intercepts_\n",
    "\n",
    "    model = ANN(x_data.shape[1], y_data.shape[1], h_layer).to(device)\n",
    "    #get the parameters of the model (these will be overridden)\n",
    "    params = model.state_dict()\n",
    "    #Generate the new state dict (weights and bias) for the pytorch model based on the weights and bias from  the sklearn weights and bias\n",
    "    temp = []\n",
    "    for i in range(len(weights)):\n",
    "    #Need to transpose the weights as they are origionally of shape  [x,y] but the state dictionary needs [y,x]\n",
    "        temp.append(torch.Tensor(weights[i]).float().T)\n",
    "        temp.append(torch.Tensor(bias[i]).float())\n",
    "    #Generate the new state dictionary\n",
    "    final = dict([(key, value) for i, (key, value) in enumerate(zip(params.keys(), temp))])\n",
    "    #Reinitilise a new model and load the new state_dict\n",
    "    model1 = ANN(x_data.shape[1], y_data.shape[1], h_layer).to(device)\n",
    "    model1.load_state_dict(final)\n",
    "    #Save the model\n",
    "    torch.save(model1.state_dict(), Filepath)\n",
    "    return model1\n",
    "\n",
    "def plot_results(model, x_test, y_test, save, file):\n",
    "    predict = model.predict(x_test)\n",
    "    t = pd.DataFrame({\"Pred\": predict.tolist(), \"y\": y_test.tolist()})\n",
    "    t.sort_values(by=['y'], inplace= True)\n",
    "\n",
    "    fig, (ax1, ax2, ax3)= plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "    plt.subplots_adjust(wspace=.4,hspace=-0.4)\n",
    "\n",
    "    ax1.plot(t['y'].tolist(), '-b', label= 'Actual Values')\n",
    "    ax1.plot(t['Pred'].tolist(), '-', color= '#c90076', label= 'Test loss')\n",
    "    ax1.set_ylabel('output')\n",
    "    ax1.set_xlabel('Array index')\n",
    "    ax1.legend(ncol=1,columnspacing=0.1,handletextpad= 0.5)\n",
    "    ax1.set_title('Train and Test Loss')\n",
    "\n",
    "    ax2.plot(residue[1:].tolist(), '-k')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('N')\n",
    "    ax2.set_title('Loss Residue')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(file)\n",
    "\n",
    "    # plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def optimise_network(x_data, y_data, split, points, layer_optimise, h_layer):\n",
    "    points += 1\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size= split, random_state=42, shuffle= True)\n",
    "    R2_train_score = np.empty(shape= (points))\n",
    "    R2_test_score = np.empty(shape= (points))\n",
    "    MSE_train_score = np.empty(shape= (points))\n",
    "    MSE_test_score = np.empty(shape= (points))\n",
    "\n",
    "    for i in range(1, int(points)):\n",
    "        if layer_optimise == 1:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "        elif layer_optimise == 2:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer[1], i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "        elif layer_optimise == 3:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer[1], h_layer[2], i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "            \n",
    "        ann.fit(x_train, y_train.ravel())\n",
    "        R2_train_score[i] = ann.score(x_train, y_train.ravel())\n",
    "        R2_test_score[i] = ann.score(x_test, y_test.ravel())\n",
    "        temp_train = root_mean_squared_error(y_train, ann.predict(x_train))\n",
    "        temp_test = root_mean_squared_error(y_test, ann.predict(x_test))\n",
    "        MSE_train_score[i] = np.power(temp_train, 2)\n",
    "        MSE_test_score[i] = np.power(temp_test, 2)\n",
    "        i += 1\n",
    "    return MSE_train_score, MSE_test_score\n",
    "        \n",
    "def optimise_graph(MSE_train, MSE_test, save, file):\n",
    "    residue = MSE_test - MSE_train\n",
    "\n",
    "    fig, (ax1, ax2)= plt.subplots(1, 2, figsize=(10,10))\n",
    "\n",
    "    plt.subplots_adjust(wspace=.4,hspace=-0.4)\n",
    "\n",
    "    ax1.plot(MSE_train.tolist(), '-k', label= 'Train loss')\n",
    "    ax1.plot(MSE_test.tolist(), '-', color= '#c90076', label= 'Test loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('N')\n",
    "    ax1.legend(ncol=1,columnspacing=0.1,handletextpad= 0.5)\n",
    "    ax1.set_title('Train and Test Loss')\n",
    "\n",
    "    ax2.plot(residue[1:].tolist(), '-k')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('N')\n",
    "    ax2.set_title('Loss Residue')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(file)\n",
    "\n",
    "    # plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def Cross_val(split_values, x_data, y_data, h_layer):\n",
    "    MSE = np.zeros(shape= (len(split_values),split_values[-1]))\n",
    "    R2 = np.zeros(shape= (len(split_values),split_values[-1]))\n",
    "    for k in split_values:\n",
    "        print(f\"========================================= Split #{k} =========================================\")  \n",
    "        kf = KFold(n_splits= k, shuffle=True, random_state= 42)\n",
    "        fold = 0\n",
    "        for train_indi, test_indi in kf.split(x_data):\n",
    "            fold += 1\n",
    "            print(f\"========================================= Fold #{fold} =========================================\")\n",
    "\n",
    "            x_train, x_test = x_data[train_indi], x_data[test_indi]\n",
    "            y_train, y_test = y_data[train_indi], y_data[test_indi]\n",
    "\n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 5000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "            ann.fit(x_train, y_train.ravel())\n",
    "            score = ann.score(x_test, y_test.ravel())\n",
    "            RMSE = root_mean_squared_error(y_test, ann.predict(x_test))\n",
    "            MSE_score = np.power(RMSE, 2)\n",
    "            R2[k-2, fold-1] = score\n",
    "            MSE[k-2, fold-1] = MSE_score\n",
    "            print(f\"R2 score: {score:.5f}, MSE score: {MSE_score:.5}, RMSE score: {RMSE:.8f}\")\n",
    "    return R2, MSE\n",
    "\n",
    "def Cross_val_plot(split_values, MSE, save, file):\n",
    "    MSE_mean = []\n",
    "    xspace = []\n",
    "    temp = []\n",
    "    x_space = np.array(np.linspace(0.5,1.2, len(split_values)))\n",
    "    j = 0\n",
    "\n",
    "    for k in split_values:\n",
    "        temp_mse = 0\n",
    "        for i in range(k):\n",
    "            temp_mse += MSE[k-2,i]\n",
    "            temp.append(MSE[k-2,i])\n",
    "            xspace.append(x_space[j])\n",
    "        temp_mse /= k\n",
    "        MSE_mean.append(temp_mse)\n",
    "        j += 1\n",
    "\n",
    "\n",
    "    colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) \n",
    "              for i in range(len(split_values))]\n",
    "    \n",
    "    markers = [int(random.choice('456789')) for i in range(len(split_values))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,9))\n",
    "    ax0 = fig.add_subplot(1, 1, 1, aspect=1.4)\n",
    "    ax0.set_xlabel('No. of cross-validation folds')\n",
    "    ax0.set_ylabel('ln (MSE)')\n",
    "\n",
    "    alpha = 1\n",
    "\n",
    "    j = 0\n",
    "    k = split_values[0]\n",
    "\n",
    "    for i in range(len(split_values)):\n",
    "        ax0.plot(xspace[j:k], np.log(MSE[i, :split_values[i]]), marker= markers[i], color= colors[i], ls= 'None', alpha= alpha)\n",
    "        ax0.plot(x_space[i], np.log(MSE_mean[i]), marker= markers[i], mec= colors[i], color= 'None', ls= 'None', alpha= alpha)\n",
    "        j = k\n",
    "        i += 1\n",
    "        if i == len(split_values):\n",
    "            break\n",
    "        k += split_values[i]\n",
    "        \n",
    "    ax0.plot(x_space,np.log(MSE_mean), '--k')\n",
    "\n",
    "    ax0.set_xticks(x_space)\n",
    "    ax0.set_xticklabels(split_values)\n",
    "\n",
    "    maximum = np.max(np.column_stack((np.log(MSE), np.log(MSE_mean))))\n",
    "    minimum = np.min(np.log(temp))\n",
    "\n",
    "    ax0.set_yticks(np.linspace(maximum, minimum - 0.05, split_values[-1]))\n",
    "    ax0.tick_params(axis='x', which='major', pad=10)\n",
    "    ax0.tick_params(which='major', length=10, width=2, direction='inout')\n",
    "\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(file)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, in_count, out_count, hidden_layer): #, learning_rate, optimizer= optim.Adam):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        input_size = in_count\n",
    "        for k in hidden_layer:\n",
    "            self.layers.append(nn.Linear(input_size, k))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            input_size = k\n",
    "        self.layers.append(nn.Linear(input_size, out_count))\n",
    "        # self.learning_rate = learning_rate\n",
    "        # self.optimizer = optimizer(params=self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Geoff's\\Desktop\\Dissertation\\Models\\No Cross Validation\"\n",
    "load_data_file = \"NIST Saturation.xlsx\"\n",
    "hidden_layer = [29]\n",
    "split_values = [2,3,4]\n",
    "\n",
    "df = Data_gather(path, load_data_file, False, True)\n",
    "df = Data_Manipulation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2)= plt.subplots(1, 2, figsize=(25,10))\n",
    "\n",
    "plt.subplots_adjust(wspace=.2,hspace=-0.4)\n",
    "plt.rc('font', size= 18)\n",
    "plt.rc('axes', labelsize= 20)\n",
    "plt.rc('xtick', labelsize= 16)\n",
    "plt.rc('ytick', labelsize= 16)\n",
    "\n",
    "ax1.plot(df['Temperature (K)'].tolist(), df['Cp (J/mol*K)'], 'ob')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_title('Adjusted Cp vs Temperature')\n",
    "ax1.set_ylim(0,3)\n",
    "\n",
    "ax2.plot(df['Pressure (bar)'].tolist(), df['Cp (J/mol*K)'] ,'ok')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_title('Adjusted Cp vs Pressure')\n",
    "ax2.set_ylim(0,3)\n",
    "\n",
    "plt.savefig('Modified Data2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Geoff's\\Desktop\\Dissertation\\Models\\No Cross Validation\"\n",
    "load_data_file = \"NIST Saturation.xlsx\"\n",
    "hidden_layer = [29]\n",
    "split_values = [2,3,4]\n",
    "\n",
    "x_data, y_data = Load_data(path= path, file_name= load_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2, MSE = Cross_val(split_values= split_values, x_data= x_data, y_data= y_data, h_layer= hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross_val_plot(split_values= split_values, MSE= MSE, save= False, file= \"ln(MSE)_vs_k_in_cross_validation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimised_MSE_train, optimised_MSE_test = optimise_network(x_data, y_data, 0.25, 10, 1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimise_graph(optimised_MSE_train, optimised_MSE_test, False, \"double_layer_train_and_test_loss_vs_neuron.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [29]\n",
    "train_test_split_value = 0.01\n",
    "save_filepath = 'test_model.pth'\n",
    "\n",
    "model = sklearn_model_generation(train_test_split_value, hidden_layer, x_data, y_data)\n",
    "save_model(x_data, y_data, hidden_layer, model, ANN, save_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
