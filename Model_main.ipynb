{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import math \n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import rdkit as rd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import AtomPairs\n",
    "from rdkit import DataStructs\n",
    "from rdkit import rdBase\n",
    "from rdkit.Chem.AtomPairs.Pairs import GetAtomPairFingerprintAsBitVect\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torcheval\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(path: str, file_name: str):\n",
    "    dataframe = Data_gather(path, file_name, False, True)\n",
    "    dataframe = Data_Manipulation(dataframe)\n",
    "    dataframe = MoleculeGen(5, dataframe, True)\n",
    "    targets = ['Cp (J/mol*K)']\n",
    "    features = (list(set(list(dataframe.columns))-set(targets)))\n",
    "    x_data = dataframe[features].values\n",
    "    y_data = dataframe[targets].values\n",
    "    \n",
    "    return x_data, y_data\n",
    "\n",
    "def Data_gather(path: str, file_name: str, CO: bool, drop_phase: bool) -> pd.DataFrame:\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    if CO == True:\n",
    "        df_CO = df[ df['Isomeric Smile'] != 'CO' ]\n",
    "        df = df.drop(df_CO.index, axis= 0)\n",
    "        \n",
    "    if drop_phase == True:\n",
    "        df_drop = df[df['Phase'] != 'liquid' ]\n",
    "        df = df.drop(df_drop.index, axis= 0)\n",
    "        df = df.drop(['Phase'], axis= 1)\n",
    "    else:\n",
    "        df['Phase'] = df['Phase'].map({'liquid': 1, 'vapor': 2})\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #Convert specific column to float64\n",
    "    #df = pd.to_numeric(df, errors='coerce')\n",
    "    #df\n",
    "\n",
    "    #search for any NaN values that may have slipped through the cracks\n",
    "    #row = df[df['Cp (J/mol*K)'].isnull()]\n",
    "    #print(row)\n",
    "    return df\n",
    "\n",
    "def MoleculeGen(rad: int, df: pd.DataFrame, Choice: bool) -> pd.DataFrame:\n",
    "    if Choice == True:\n",
    "        mol_list = []\n",
    "        fin_list = []\n",
    "        for smile in df['Isomeric Smile']:\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(smile)\n",
    "                mol_list.append(mol)\n",
    "                mf_bitvect = AllChem.GetMorganFingerprintAsBitVect(mol, radius=rad, nBits = 256)\n",
    "                temp_arr = np.zeros((0,), dtype=np.int8)\n",
    "                DataStructs.ConvertToNumpyArray(mf_bitvect, temp_arr)\n",
    "                fin_list.append(temp_arr)\n",
    "            except:\n",
    "                print(smile)\n",
    "        fin_list = pd.DataFrame(fin_list)\n",
    "        df = pd.concat([df, fin_list], axis= 1)\n",
    "    df = df.drop(['Isomeric Smile'], axis= 1)\n",
    "    return df\n",
    "\n",
    "def Data_Manipulation(df: pd.DataFrame) -> pd.DataFrame:    \n",
    "    Temperature = df['Temperature (K)'].values\n",
    "    Pressure = df['Pressure (bar)'].values\n",
    "    Tc = df['Tc'].values\n",
    "    Pc = df['Pc'].values\n",
    "    CP = df['Cp (J/mol*K)'].values\n",
    "    Isom = df['Isomeric Smile'].values\n",
    "    df = df.drop(['Isomeric Smile', 'Density (kg/m3)', 'Temperature (K)', 'Pressure (bar)', 'Cp (J/mol*K)', 'Tc', 'Pc'], axis= 1)\n",
    "    \n",
    "    Tr = Temperature/Tc\n",
    "    Pr = Pressure/Pc\n",
    "\n",
    "    temp = {'Isomeric Smile': Isom, 'Tr': Tr, 'Pr': Pr, 'Cp': CP}\n",
    "    temp = pd.DataFrame(temp)\n",
    "    df_drop = temp[temp['Tr'] >= 0.999]\n",
    "    temp = temp.drop(df_drop.index, axis= 0)\n",
    "    df_drop = temp[temp['Pr'] >= 0.999]\n",
    "    temp = temp.drop(df_drop.index, axis= 0)\n",
    "    temp = temp.reset_index(drop=True)\n",
    "\n",
    "    Isom = temp['Isomeric Smile'].values\n",
    "    Tr = temp['Tr'].values\n",
    "    Pr = temp['Pr'].values \n",
    "    CP = temp['Cp'].values\n",
    "\n",
    "    Temperature = np.power(np.arctanh(np.power(Tr, 29.12522)), 0.688902)\n",
    "    Pressure = np.power(np.arctanh(np.power(Pr, 0.99928)), 1.162695504)\n",
    "    CP = np.sqrt(np.log(np.power(np.log(CP), 1/3.061115817107)))\n",
    "    \n",
    "    temp = {'Isomeric Smile': Isom, 'Temperature (K)': Temperature, 'Pressure (bar)': Pressure, 'Cp (J/mol*K)': CP}\n",
    "    temp = pd.DataFrame(temp)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "\n",
    "def sklearn_model_generation(split, h_layer, x_data, y_data):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size= split, random_state=42, shuffle= True)\n",
    "    \n",
    "    ann_sklearn = MLPRegressor(hidden_layer_sizes= (h_layer), \n",
    "            activation= 'relu',\n",
    "            solver= 'adam',\n",
    "            alpha= 1e-4,\n",
    "            max_iter= 5000,\n",
    "            shuffle= True,\n",
    "            random_state= 42,\n",
    "            early_stopping= True\n",
    "            )\n",
    "    \n",
    "    ann_sklearn.fit(x_train, y_train.ravel())\n",
    "\n",
    "    score = ann_sklearn.score(x_test,y_test.ravel())\n",
    "    predict_test_set = ann_sklearn.predict(x_test)\n",
    "    RMSE = root_mean_squared_error(y_test, predict_test_set)\n",
    "    MSE = np.power(RMSE, 2)\n",
    "    print(f'R2 = {score}')\n",
    "    print(f'MSE = {MSE}')\n",
    "    print(f'RMSE = {RMSE}')\n",
    "    return ann_sklearn\n",
    "\n",
    "def save_model(x_data, y_data, h_layer, ann_sklearn, ANN, Filepath):\n",
    "    weights = ann_sklearn.coeffs_\n",
    "    bias = ann_sklearn.intercepts_\n",
    "\n",
    "    model = ANN(x_data.shape[1], y_data.shape[1], h_layer).to(device)\n",
    "    #get the parameters of the model (these will be overridden)\n",
    "    params = model.state_dict()\n",
    "    #Generate the new state dict (weights and bias) for the pytorch model based on the weights and bias from  the sklearn weights and bias\n",
    "    temp = []\n",
    "    for i in range(len(weights)):\n",
    "    #Need to transpose the weights as they are origionally of shape  [x,y] but the state dictionary needs [y,x]\n",
    "        temp.append(torch.Tensor(weights[i]).float().T)\n",
    "        temp.append(torch.Tensor(bias[i]).float())\n",
    "    #Generate the new state dictionary\n",
    "    final = dict([(key, value) for i, (key, value) in enumerate(zip(params.keys(), temp))])\n",
    "    #Reinitilise a new model and load the new state_dict\n",
    "    model1 = ANN(x_data.shape[1], y_data.shape[1], h_layer).to(device)\n",
    "    model1.load_state_dict(final)\n",
    "    #Save the model\n",
    "    torch.save(model1.state_dict(), Filepath)\n",
    "    return model1\n",
    "\n",
    "def optimise_network(x_data, y_data, split, points, layer_optimise, h_layer, save, file):\n",
    "    points += 1\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size= split, random_state=42, shuffle= True)\n",
    "    R2_train_score = np.empty(shape= (points))\n",
    "    R2_test_score = np.empty(shape= (points))\n",
    "    MSE_train_score = np.empty(shape= (points))\n",
    "    MSE_test_score = np.empty(shape= (points))\n",
    "\n",
    "    for i in range(1, int(points)):\n",
    "        if layer_optimise == 1:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "        elif layer_optimise == 2:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer[1], i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "        elif layer_optimise == 3:    \n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer[1], h_layer[2], i), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 2000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "            \n",
    "        ann.fit(x_train, y_train.ravel())\n",
    "        R2_train_score[i] = ann.score(x_train, y_train.ravel())\n",
    "        R2_test_score[i] = ann.score(x_test, y_test.ravel())\n",
    "        temp_train = root_mean_squared_error(y_train, ann.predict(x_train))\n",
    "        temp_test = root_mean_squared_error(y_test, ann.predict(x_test))\n",
    "        MSE_train_score[i] = np.power(temp_train, 2)\n",
    "        MSE_test_score[i] = np.power(temp_test, 2)\n",
    "        i += 1\n",
    "\n",
    "    residue = MSE_test_score - MSE_train_score\n",
    "\n",
    "    fig= plt.figure(figsize=(10,9))\n",
    "    ax1 = fig.add_subplot(2, 1, 1, aspect='equal')\n",
    "    ax2 = fig.add_subplot(2, 1, 2, aspect='equal')\n",
    "\n",
    "    plt.subplots_adjust(wspace=.4,hspace=-0.4)\n",
    "\n",
    "    # ax1.text(-0.35,0.9,'(a) Train and Test loss',transform=ax1.transAxes)\n",
    "    # ax2.text(-0.35,0.9,'(b) loss residue',transform=ax2.transAxes)\n",
    "\n",
    "    ax1.plot(MSE_train_score[1:].tolist(), '-k', label= 'Train loss')\n",
    "    ax1.plot(MSE_test_score[1:].tolist(), '-', color= '#c90076', label= 'Test loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('N')\n",
    "    ax1.set_ylim([0,1e-4])\n",
    "    # ax1.legend(ncol=2,columnspacing=0.1,handletextpad=-0.2)\n",
    "    \n",
    "        \n",
    "    ax2.plot(residue[1:].tolist(), '-k')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('N')\n",
    "\n",
    "    if save == True:\n",
    "        plt.savefig(file)\n",
    "\n",
    "    # plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def Cross_val(split_values, x_data, y_data, h_layer):\n",
    "    MSE = np.zeros(shape= (len(split_values),split_values[-1]))\n",
    "    R2 = np.zeros(shape= (len(split_values),split_values[-1]))\n",
    "    for k in split_values:\n",
    "        print(f\"========================================= Split #{k} =========================================\")  \n",
    "        kf = KFold(n_splits= k, shuffle=True, random_state= 42)\n",
    "        fold = 0\n",
    "        for train_indi, test_indi in kf.split(x_data):\n",
    "            fold += 1\n",
    "            print(f\"========================================= Fold #{fold} =========================================\")\n",
    "\n",
    "            x_train, x_test = x_data[train_indi], x_data[test_indi]\n",
    "            y_train, y_test = y_data[train_indi], y_data[test_indi]\n",
    "\n",
    "            ann = MLPRegressor(hidden_layer_sizes= (h_layer), \n",
    "                        activation= 'relu',\n",
    "                        solver= 'adam',\n",
    "                        alpha= 1e-4,\n",
    "                        max_iter= 5000,\n",
    "                        shuffle= True,\n",
    "                        random_state= 42,\n",
    "                        early_stopping= True\n",
    "                        )\n",
    "            ann.fit(x_train, y_train.ravel())\n",
    "            score = ann.score(x_test, y_test.ravel())\n",
    "            RMSE = root_mean_squared_error(y_test, ann.predict(x_test))\n",
    "            MSE_score = np.power(RMSE, 2)\n",
    "            R2[k-2, fold-1] = score\n",
    "            MSE[k-2, fold-1] = MSE_score\n",
    "            print(f\"R2 score: {score:.5f}, MSE score: {MSE_score:.5}, RMSE score: {RMSE:.8f}\")\n",
    "    return R2, MSE\n",
    "\n",
    "def Cross_val_plot(split_values, MSE, save, file):\n",
    "    MSE_mean = []\n",
    "    xspace = []\n",
    "    temp = []\n",
    "    x_space = np.array(np.linspace(0.5,1.2, len(split_values)))\n",
    "    j = 0\n",
    "\n",
    "    for k in split_values:\n",
    "        temp_mse = 0\n",
    "        for i in range(k):\n",
    "            temp_mse += MSE[k-2,i]\n",
    "            temp.append(MSE[k-2,i])\n",
    "            xspace.append(x_space[j])\n",
    "        temp_mse /= k\n",
    "        MSE_mean.append(temp_mse)\n",
    "        j += 1\n",
    "\n",
    "\n",
    "    colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                for i in range(len(split_values))]\n",
    "    \n",
    "    markers = [int(random.choice('456789')) for i in range(len(split_values))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,9))\n",
    "    ax0 = fig.add_subplot(1, 1, 1, aspect=1.4)\n",
    "    ax0.set_xlabel('No. of cross-validation folds')\n",
    "    ax0.set_ylabel('ln (MSE)')\n",
    "\n",
    "    alpha = 1\n",
    "\n",
    "    j = 0\n",
    "    k = split_values[0]\n",
    "\n",
    "    for i in range(len(split_values)):\n",
    "        ax0.plot(xspace[j:k], np.log(MSE[i, :split_values[i]]), marker= markers[i], color= colors[i], ls= 'None', alpha= alpha)\n",
    "        ax0.plot(x_space[i], np.log(MSE_mean[i]), marker= markers[i], mec= colors[i], color= 'None', ls= 'None', alpha= alpha)\n",
    "        j = k\n",
    "        i += 1\n",
    "        if i == len(split_values):\n",
    "            break\n",
    "        k += split_values[i]\n",
    "        \n",
    "    ax0.plot(x_space,np.log(MSE_mean), '--k')\n",
    "\n",
    "    ax0.set_xticks(x_space)\n",
    "    ax0.set_xticklabels(split_values)\n",
    "\n",
    "    maximum = np.max(np.column_stack((np.log(MSE), np.log(MSE_mean))))\n",
    "    minimum = np.min(np.log(temp))\n",
    "\n",
    "    ax0.set_yticks(np.linspace(maximum, minimum - 0.05, split_values[-1]))\n",
    "    ax0.tick_params(axis='x', which='major', pad=10)\n",
    "    ax0.tick_params(which='major', length=10, width=2, direction='inout')\n",
    "\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(file)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, in_count, out_count, hidden_layer): #, learning_rate, optimizer= optim.Adam):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        input_size = in_count\n",
    "        for k in hidden_layer:\n",
    "            self.layers.append(nn.Linear(input_size, k))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            input_size = k\n",
    "        self.layers.append(nn.Linear(input_size, out_count))\n",
    "        # self.learning_rate = learning_rate\n",
    "        # self.optimizer = optimizer(params=self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Geoff's\\Desktop\\Dissertation\\Models\\No Cross Validation\"\n",
    "load_data_file = \"NIST Saturation.xlsx\"\n",
    "hidden_layer = [29]\n",
    "split_values = [2,3,4]\n",
    "\n",
    "x_data, y_data = Load_data(path= path, file_name= load_data_file)\n",
    "R2, MSE = Cross_val(split_values= split_values, x_data= x_data, y_data= y_data, h_layer= hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross_val_plot(split_values= split_values, MSE= MSE, save= False, file= \"ln(MSE)_vs_k_in_cross_validation.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[           nan 2.55104230e-05 1.53654536e-06 2.51017195e-06\n",
      " 3.36123582e-06 3.30350915e-06 2.33122299e-06 3.08225958e-06\n",
      " 2.21681404e-06 7.69558907e-07 2.99902771e-07]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimise_network(x_data, y_data, 0.25, 10, 1, [], False, \"double_layer_train_and_test_loss_vs_neuron.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [29]\n",
    "train_test_split_value = 0.01\n",
    "save_filepath = 'test_model.pth'\n",
    "\n",
    "model = sklearn_model_generation(train_test_split_value, hidden_layer, x_data, y_data)\n",
    "save_model(x_data, y_data, hidden_layer, model, ANN, save_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
